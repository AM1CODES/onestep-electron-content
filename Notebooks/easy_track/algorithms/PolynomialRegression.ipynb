{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.00727,
     "end_time": "2020-08-29T14:58:47.268954",
     "exception": false,
     "start_time": "2020-08-29T14:58:47.261684",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Polynomial Regression\n",
    "---\n",
    "In this notebook we will take a look at another regression model â€” Polynomial Regression. It's actually very closely related to the Linear Regression algorithm that we saw earlier. In polynomial regression, we fit a polynomial equation on the data with a curvilinear relationship between the target variable and the independent variables.\n",
    "The value of the target (y) changes in a non-uniform manner with respect to the independent variable(x). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.00635,
     "end_time": "2020-08-29T14:58:47.281403",
     "exception": false,
     "start_time": "2020-08-29T14:58:47.275053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Importing Project Dependencies\n",
    "---\n",
    "\n",
    "Let us begin by importing all the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-08-29T14:58:47.302431Z",
     "iopub.status.busy": "2020-08-29T14:58:47.301565Z",
     "iopub.status.idle": "2020-08-29T14:58:48.873583Z",
     "shell.execute_reply": "2020-08-29T14:58:48.872780Z"
    },
    "papermill": {
     "duration": 1.585767,
     "end_time": "2020-08-29T14:58:48.873736",
     "exception": false,
     "start_time": "2020-08-29T14:58:47.287969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Dataset\n",
    "---\n",
    "In this notebook we will use the fuel consumption data for polynomial regression modeling, which contains model-specific fuel consumption ratings and estimated carbon dioxide emissions for new light-duty vehicles for retail sale in Canada.\n",
    "\n",
    "- **MODELYEAR** e.g. 2014\n",
    "- **MAKE** e.g. Acura\n",
    "- **MODEL** e.g. ILX\n",
    "- **VEHICLE CLASS** e.g. SUV\n",
    "- **ENGINE SIZE** e.g. 4.7\n",
    "- **CYLINDERS** e.g 6\n",
    "- **TRANSMISSION** e.g. A6\n",
    "- **FUEL CONSUMPTION in CITY(L/100 km)** e.g. 9.9\n",
    "- **FUEL CONSUMPTION in HWY (L/100 km)** e.g. 8.9\n",
    "- **FUEL CONSUMPTION COMB (L/100 km)** e.g. 9.2\n",
    "- **CO2 EMISSIONS (g/km)** e.g. 182   --> low --> 0\n",
    "\n",
    "**Goal:-**\n",
    "* Predicting the CO<sub>2</sub> emissions generated by the vehicles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-08-29T14:58:48.898907Z",
     "iopub.status.busy": "2020-08-29T14:58:48.897563Z",
     "iopub.status.idle": "2020-08-29T14:58:48.918183Z",
     "shell.execute_reply": "2020-08-29T14:58:48.918831Z"
    },
    "papermill": {
     "duration": 0.039054,
     "end_time": "2020-08-29T14:58:48.919006",
     "exception": false,
     "start_time": "2020-08-29T14:58:48.879952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   MODELYEAR   MAKE       MODEL VEHICLECLASS  ENGINESIZE  CYLINDERS  \\\n",
       "0       2014  ACURA         ILX      COMPACT         2.0          4   \n",
       "1       2014  ACURA         ILX      COMPACT         2.4          4   \n",
       "2       2014  ACURA  ILX HYBRID      COMPACT         1.5          4   \n",
       "3       2014  ACURA     MDX 4WD  SUV - SMALL         3.5          6   \n",
       "4       2014  ACURA     RDX AWD  SUV - SMALL         3.5          6   \n",
       "\n",
       "  TRANSMISSION FUELTYPE  FUELCONSUMPTION_CITY  FUELCONSUMPTION_HWY  \\\n",
       "0          AS5        Z                   9.9                  6.7   \n",
       "1           M6        Z                  11.2                  7.7   \n",
       "2          AV7        Z                   6.0                  5.8   \n",
       "3          AS6        Z                  12.7                  9.1   \n",
       "4          AS6        Z                  12.1                  8.7   \n",
       "\n",
       "   FUELCONSUMPTION_COMB  FUELCONSUMPTION_COMB_MPG  CO2EMISSIONS  \n",
       "0                   8.5                        33           196  \n",
       "1                   9.6                        29           221  \n",
       "2                   5.9                        48           136  \n",
       "3                  11.1                        25           255  \n",
       "4                  10.6                        27           244  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MODELYEAR</th>\n      <th>MAKE</th>\n      <th>MODEL</th>\n      <th>VEHICLECLASS</th>\n      <th>ENGINESIZE</th>\n      <th>CYLINDERS</th>\n      <th>TRANSMISSION</th>\n      <th>FUELTYPE</th>\n      <th>FUELCONSUMPTION_CITY</th>\n      <th>FUELCONSUMPTION_HWY</th>\n      <th>FUELCONSUMPTION_COMB</th>\n      <th>FUELCONSUMPTION_COMB_MPG</th>\n      <th>CO2EMISSIONS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2014</td>\n      <td>ACURA</td>\n      <td>ILX</td>\n      <td>COMPACT</td>\n      <td>2.0</td>\n      <td>4</td>\n      <td>AS5</td>\n      <td>Z</td>\n      <td>9.9</td>\n      <td>6.7</td>\n      <td>8.5</td>\n      <td>33</td>\n      <td>196</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2014</td>\n      <td>ACURA</td>\n      <td>ILX</td>\n      <td>COMPACT</td>\n      <td>2.4</td>\n      <td>4</td>\n      <td>M6</td>\n      <td>Z</td>\n      <td>11.2</td>\n      <td>7.7</td>\n      <td>9.6</td>\n      <td>29</td>\n      <td>221</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2014</td>\n      <td>ACURA</td>\n      <td>ILX HYBRID</td>\n      <td>COMPACT</td>\n      <td>1.5</td>\n      <td>4</td>\n      <td>AV7</td>\n      <td>Z</td>\n      <td>6.0</td>\n      <td>5.8</td>\n      <td>5.9</td>\n      <td>48</td>\n      <td>136</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2014</td>\n      <td>ACURA</td>\n      <td>MDX 4WD</td>\n      <td>SUV - SMALL</td>\n      <td>3.5</td>\n      <td>6</td>\n      <td>AS6</td>\n      <td>Z</td>\n      <td>12.7</td>\n      <td>9.1</td>\n      <td>11.1</td>\n      <td>25</td>\n      <td>255</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2014</td>\n      <td>ACURA</td>\n      <td>RDX AWD</td>\n      <td>SUV - SMALL</td>\n      <td>3.5</td>\n      <td>6</td>\n      <td>AS6</td>\n      <td>Z</td>\n      <td>12.1</td>\n      <td>8.7</td>\n      <td>10.6</td>\n      <td>27</td>\n      <td>244</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "#importing our data set\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/OneStep-elecTRON/ContentSection/main/Datasets/fuel_consumption_co2.csv')\n",
    "\n",
    "#checking the top 5 rows in our data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us have a look at the basic info regarding our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T14:58:49.014202Z",
     "iopub.status.busy": "2020-08-29T14:58:49.013006Z",
     "iopub.status.idle": "2020-08-29T14:58:49.019812Z",
     "shell.execute_reply": "2020-08-29T14:58:49.020789Z"
    },
    "papermill": {
     "duration": 0.039699,
     "end_time": "2020-08-29T14:58:49.021051",
     "exception": false,
     "start_time": "2020-08-29T14:58:48.981352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1067 entries, 0 to 1066\nData columns (total 13 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   MODELYEAR                 1067 non-null   int64  \n 1   MAKE                      1067 non-null   object \n 2   MODEL                     1067 non-null   object \n 3   VEHICLECLASS              1067 non-null   object \n 4   ENGINESIZE                1067 non-null   float64\n 5   CYLINDERS                 1067 non-null   int64  \n 6   TRANSMISSION              1067 non-null   object \n 7   FUELTYPE                  1067 non-null   object \n 8   FUELCONSUMPTION_CITY      1067 non-null   float64\n 9   FUELCONSUMPTION_HWY       1067 non-null   float64\n 10  FUELCONSUMPTION_COMB      1067 non-null   float64\n 11  FUELCONSUMPTION_COMB_MPG  1067 non-null   int64  \n 12  CO2EMISSIONS              1067 non-null   int64  \ndtypes: float64(4), int64(4), object(5)\nmemory usage: 108.5+ KB\n"
     ]
    }
   ],
   "source": [
    "#checking different column info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are no null values within our dataset. Now, let us have a look at the statistical analysis of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T14:58:49.080345Z",
     "iopub.status.busy": "2020-08-29T14:58:49.079500Z",
     "iopub.status.idle": "2020-08-29T14:58:49.140973Z",
     "shell.execute_reply": "2020-08-29T14:58:49.140070Z"
    },
    "papermill": {
     "duration": 0.08076,
     "end_time": "2020-08-29T14:58:49.141137",
     "exception": false,
     "start_time": "2020-08-29T14:58:49.060377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       MODELYEAR   ENGINESIZE    CYLINDERS  FUELCONSUMPTION_CITY  \\\n",
       "count     1067.0  1067.000000  1067.000000           1067.000000   \n",
       "mean      2014.0     3.346298     5.794752             13.296532   \n",
       "std          0.0     1.415895     1.797447              4.101253   \n",
       "min       2014.0     1.000000     3.000000              4.600000   \n",
       "25%       2014.0     2.000000     4.000000             10.250000   \n",
       "50%       2014.0     3.400000     6.000000             12.600000   \n",
       "75%       2014.0     4.300000     8.000000             15.550000   \n",
       "max       2014.0     8.400000    12.000000             30.200000   \n",
       "\n",
       "       FUELCONSUMPTION_HWY  FUELCONSUMPTION_COMB  FUELCONSUMPTION_COMB_MPG  \\\n",
       "count          1067.000000           1067.000000               1067.000000   \n",
       "mean              9.474602             11.580881                 26.441425   \n",
       "std               2.794510              3.485595                  7.468702   \n",
       "min               4.900000              4.700000                 11.000000   \n",
       "25%               7.500000              9.000000                 21.000000   \n",
       "50%               8.800000             10.900000                 26.000000   \n",
       "75%              10.850000             13.350000                 31.000000   \n",
       "max              20.500000             25.800000                 60.000000   \n",
       "\n",
       "       CO2EMISSIONS  \n",
       "count   1067.000000  \n",
       "mean     256.228679  \n",
       "std       63.372304  \n",
       "min      108.000000  \n",
       "25%      207.000000  \n",
       "50%      251.000000  \n",
       "75%      294.000000  \n",
       "max      488.000000  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MODELYEAR</th>\n      <th>ENGINESIZE</th>\n      <th>CYLINDERS</th>\n      <th>FUELCONSUMPTION_CITY</th>\n      <th>FUELCONSUMPTION_HWY</th>\n      <th>FUELCONSUMPTION_COMB</th>\n      <th>FUELCONSUMPTION_COMB_MPG</th>\n      <th>CO2EMISSIONS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1067.0</td>\n      <td>1067.000000</td>\n      <td>1067.000000</td>\n      <td>1067.000000</td>\n      <td>1067.000000</td>\n      <td>1067.000000</td>\n      <td>1067.000000</td>\n      <td>1067.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2014.0</td>\n      <td>3.346298</td>\n      <td>5.794752</td>\n      <td>13.296532</td>\n      <td>9.474602</td>\n      <td>11.580881</td>\n      <td>26.441425</td>\n      <td>256.228679</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.0</td>\n      <td>1.415895</td>\n      <td>1.797447</td>\n      <td>4.101253</td>\n      <td>2.794510</td>\n      <td>3.485595</td>\n      <td>7.468702</td>\n      <td>63.372304</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>2014.0</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>4.600000</td>\n      <td>4.900000</td>\n      <td>4.700000</td>\n      <td>11.000000</td>\n      <td>108.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2014.0</td>\n      <td>2.000000</td>\n      <td>4.000000</td>\n      <td>10.250000</td>\n      <td>7.500000</td>\n      <td>9.000000</td>\n      <td>21.000000</td>\n      <td>207.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2014.0</td>\n      <td>3.400000</td>\n      <td>6.000000</td>\n      <td>12.600000</td>\n      <td>8.800000</td>\n      <td>10.900000</td>\n      <td>26.000000</td>\n      <td>251.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2014.0</td>\n      <td>4.300000</td>\n      <td>8.000000</td>\n      <td>15.550000</td>\n      <td>10.850000</td>\n      <td>13.350000</td>\n      <td>31.000000</td>\n      <td>294.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2014.0</td>\n      <td>8.400000</td>\n      <td>12.000000</td>\n      <td>30.200000</td>\n      <td>20.500000</td>\n      <td>25.800000</td>\n      <td>60.000000</td>\n      <td>488.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Gives a statistical analysis of the data in each column\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007897,
     "end_time": "2020-08-29T14:58:49.157572",
     "exception": false,
     "start_time": "2020-08-29T14:58:49.149675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that we have checked for null values and checked for the important information relevant to different columns, its time for us to go and make our model. Let's start by defining our featues and target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T14:58:49.185250Z",
     "iopub.status.busy": "2020-08-29T14:58:49.184120Z",
     "iopub.status.idle": "2020-08-29T14:58:49.188520Z",
     "shell.execute_reply": "2020-08-29T14:58:49.187626Z"
    },
    "papermill": {
     "duration": 0.022212,
     "end_time": "2020-08-29T14:58:49.188677",
     "exception": false,
     "start_time": "2020-08-29T14:58:49.166465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_df = df[['ENGINESIZE', 'FUELCONSUMPTION_CITY', 'FUELCONSUMPTION_HWY', 'FUELCONSUMPTION_COMB', 'FUELCONSUMPTION_COMB_MPG', 'CO2EMISSIONS']]\n",
    "\n",
    "X = df[['ENGINESIZE', 'FUELCONSUMPTION_CITY', 'FUELCONSUMPTION_HWY', 'FUELCONSUMPTION_COMB', 'FUELCONSUMPTION_COMB_MPG']]\n",
    "y = df[['CO2EMISSIONS']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us split the data into training and test sets. For this, we will be using sklearn's built-in data splitting method train_test_split method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T14:58:49.214474Z",
     "iopub.status.busy": "2020-08-29T14:58:49.213145Z",
     "iopub.status.idle": "2020-08-29T14:58:49.219516Z",
     "shell.execute_reply": "2020-08-29T14:58:49.218738Z"
    },
    "papermill": {
     "duration": 0.022669,
     "end_time": "2020-08-29T14:58:49.219673",
     "exception": false,
     "start_time": "2020-08-29T14:58:49.197004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((853, 5), (853, 1), (214, 5), (214, 1))"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Step 1- Importing train_test_split method\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 2- Performing the data split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state  =101)\n",
    "\n",
    "# Step 3- Printing and checking the shape of the splits\n",
    "X_train.shape , y_train.shape , X_test.shape , y_test.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008037,
     "end_time": "2020-08-29T14:58:49.266510",
     "exception": false,
     "start_time": "2020-08-29T14:58:49.258473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that we are done pre-processing the data, let us start working on creating and training our models.\n",
    "\n",
    "## Modeling\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will create a simple linear regression model, followed by a polynomial regression model, which will help us to see the improvement in performance, if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T14:58:49.296078Z",
     "iopub.status.busy": "2020-08-29T14:58:49.295222Z",
     "iopub.status.idle": "2020-08-29T14:58:49.432997Z",
     "shell.execute_reply": "2020-08-29T14:58:49.433706Z"
    },
    "papermill": {
     "duration": 0.158505,
     "end_time": "2020-08-29T14:58:49.433881",
     "exception": false,
     "start_time": "2020-08-29T14:58:49.275376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean absolute error = 14.289719626168225\nMean squared error = 404.2710280373832\n"
     ]
    }
   ],
   "source": [
    "# Step 1- Importing linear regression model class from sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Step 2- Creating model class object\n",
    "model = LinearRegression()\n",
    "\n",
    "# Step 3- Training linear regression model\n",
    "model = model.fit(X_train,y_train)\n",
    "\n",
    "# Step 4- Evaluating the trained model\n",
    "y_preds = model.predict(X_test)\n",
    "y_preds = np.round(y_preds) # rounding up predictions to nearest integer value\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "print(\"Mean absolute error =\", mean_absolute_error(y_test, y_preds))\n",
    "print(\"Mean squared error =\", mean_squared_error(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create another model, this time a polynomial regression one. Now, the Scikit Learn library doesn't come with a polynomial regression model class. So, will first transform the data into a polynomial form, then we will fit this transformed data to a linear regression model. The end result of this will be a polynomial regression model. Let's see how to implement this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T14:58:49.501824Z",
     "iopub.status.busy": "2020-08-29T14:58:49.500380Z",
     "iopub.status.idle": "2020-08-29T14:58:49.531312Z",
     "shell.execute_reply": "2020-08-29T14:58:49.532350Z"
    },
    "papermill": {
     "duration": 0.054147,
     "end_time": "2020-08-29T14:58:49.532608",
     "exception": false,
     "start_time": "2020-08-29T14:58:49.478461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean absolute error = 9.70713172061367\nMean squared error = 258.2293567470115\n"
     ]
    }
   ],
   "source": [
    "# Step 1- Importing the polynomial transformation class\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Step 2- Creating the transformer class object\n",
    "poly_transform = PolynomialFeatures(degree = 2) # will convert to a second degree equation\n",
    "\n",
    "# Step 3- Performing polynomial transformation\n",
    "X_train_poly = poly_transform.fit_transform(X_train)\n",
    "\n",
    "# Step 4- Fitting transformed data to linear model\n",
    "lin_reg_2=LinearRegression()\n",
    "lin_reg_2.fit(X_train_poly, y_train)\n",
    "\n",
    "# Step 5- Evaluating the model\n",
    "X_test_poly = poly_transform.fit_transform(X_test)\n",
    "y_preds = lin_reg_2.predict(X_test_poly)\n",
    "\n",
    "print(\"Mean absolute error =\", mean_absolute_error(y_test, y_preds))\n",
    "print(\"Mean squared error =\", mean_squared_error(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the total error (which denotes the information loss while making the predictions) generated by the model as compared to the simple linear model has already reduced significantly. You can experiment with polynomial equations of different degrees and compare the results, choosing the one that gives you the lowest loss on both test and training set while also making sure that you are not overfitting.  \n",
    "\n",
    "With this, we come to the end of our polynomial regression tutorial. Go through the tutorial once again before moving on to the quiz. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "papermill": {
   "duration": 8.124734,
   "end_time": "2020-08-29T14:58:49.671753",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-08-29T14:58:41.547019",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}